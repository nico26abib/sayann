#!/usr/bin/env python3
"""
Test du browser en mode VISIBLE pour debugging
"""
import asyncio
import sys
from pathlib import Path

# Ajoute le r√©pertoire parent au path pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

async def test_google_search():
    print("üåê D√©marrage du navigateur (VISIBLE)...")
    
    # Trouve Chrome local
    import config
    chrome_path = config.get_chrome_path()
    
    if chrome_path:
        print(f"‚úÖ Chrome local trouv√©: {chrome_path}")
    else:
        print("‚ö†Ô∏è  Chrome local non trouv√©, utilisation de Chromium embarqu√©")
    
    playwright = await async_playwright().start()
    
    launch_options = {
        "headless": False,  # VISIBLE
        "slow_mo": 1000  # Ralenti pour voir ce qui se passe
    }
    
    if chrome_path:
        launch_options["executable_path"] = chrome_path
    
    browser = await playwright.chromium.launch(**launch_options)
    
    context = await browser.new_context(
        user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    )
    
    page = await context.new_page()
    
    try:
        query = "S&P 500 index live"
        search_url = f"https://www.google.com/search?q={query.replace(' ', '+')}"
        
        print(f"üìù Recherche: {query}")
        print(f"üîó URL: {search_url}")
        print("\n‚è≥ Navigation en cours... (regarde le navigateur)")
        
        await page.goto(search_url, timeout=30000)
        await page.wait_for_load_state("domcontentloaded")
        
        print("‚úÖ Page charg√©e!")
        
        # Attends 3 secondes pour que tu puisses voir
        await asyncio.sleep(3)
        
        # Screenshot
        await page.screenshot(path="debug_google.png")
        print("üì∏ Screenshot sauvegard√©: debug_google.png")
        
        # Extraire le contenu
        content = await page.content()
        soup = BeautifulSoup(content, 'html.parser')
        
        # Sauvegarder le HTML brut
        with open("debug_google.html", "w", encoding="utf-8") as f:
            f.write(content)
        print("üíæ HTML sauvegard√©: debug_google.html")
        
        # Chercher les r√©sultats
        print("\nüîç Recherche de r√©sultats...")
        
        # Strategy 1: Divs avec class 'g'
        results = soup.find_all('div', class_='g')
        print(f"   Strategy 1 - class='g': {len(results)} trouv√©s")
        
        # Strategy 2: Featured snippets
        featured = soup.find_all('div', class_=['kp-header', 'IZ6rdc', 'kCrYT'])
        print(f"   Strategy 2 - featured: {len(featured)} trouv√©s")
        
        # Strategy 3: h3 tags (titres)
        h3s = soup.find_all('h3')
        print(f"   Strategy 3 - h3 tags: {len(h3s)} trouv√©s")
        
        # Afficher les 3 premiers h3
        print("\nüìÑ Premiers titres trouv√©s:")
        for i, h3 in enumerate(h3s[:5], 1):
            print(f"   {i}. {h3.get_text()[:100]}")
        
        # Chercher des prix / chiffres
        print("\nüí∞ Recherche de chiffres/prix...")
        text = soup.get_text()
        import re
        numbers = re.findall(r'\d+[,\.]\d+', text)[:10]
        print(f"   Chiffres trouv√©s: {numbers}")
        
        print("\n‚è∏  Le navigateur reste ouvert 10 secondes pour inspection...")
        await asyncio.sleep(10)
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await browser.close()
        await playwright.stop()
        print("\n‚úÖ Test termin√©")

if __name__ == "__main__":
    asyncio.run(test_google_search())

